import telebot
import pandas as pd
import uuid
import random
import os
from telebot.types import InlineKeyboardMarkup, InlineKeyboardButton, InlineQueryResultArticle, InputTextMessageContent
from g4f import ChatCompletion, Provider
import threading
import time
import logging

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Configure providers
ACTIVE_PROVIDERS = [
    Provider.Copilot,
    Provider.Yqcloud,
    Provider.ChatGptEs,
    Provider.PollinationsAI,
    Provider.Glider,
    Provider.Liaobots,
    Provider.Phind,
]

# Global cache for models: [{"name": "gpt-4", "state": "enable|disable|checking", "rate": response_time}]
MODELS_TO_CHECK = []

# Global dictionary to track cancellation requests
cancel_flags = {}

class AutoProvider:
    def __init__(self, providers):
        self.providers = providers
        self.current_provider = None
        self.last_failure = {}
        self.retry_delay = 300  # 5 minutes in seconds

    def get_provider(self):
        current_time = time.time()
        if self.current_provider:
            last_fail_time = self.last_failure.get(self.current_provider.__name__, 0)
            if current_time - last_fail_time > self.retry_delay:
                return self.current_provider
            self.current_provider = None
        for provider in self.providers:
            last_fail_time = self.last_failure.get(provider.__name__, 0)
            if current_time - last_fail_time > self.retry_delay:
                self.current_provider = provider
                return provider
        # raise Exception("All providers are temporarily unavailable")

    def mark_failed(self, provider):
        self.last_failure[provider.__name__] = time.time()
        self.current_provider = None

auto_provider = AutoProvider(ACTIVE_PROVIDERS)

### Model Cache Functions
def extract_models_from_providers():
    """Extract unique models from all active providers."""
    all_models = set()
    for provider in ACTIVE_PROVIDERS:
        try:
            if hasattr(provider, 'models'):
                provider_models = provider.models
            elif hasattr(provider, 'get_models'):
                provider_models = provider.get_models()
            else:
                provider_models = ["gpt-4", "gpt-3.5-turbo", "gpt-4o"]
            all_models.update(provider_models)
        except Exception as e:
            logger.warning(f"Failed to extract models from {provider.__name__}: {str(e)}")
    return list(all_models)

def is_model_active(model):
    """Test if a model is active. Returns (is_active, response_time)."""
    messages = [{"role": "user", "content": "Hello"}]
    retries = len(ACTIVE_PROVIDERS)
    for attempt in range(retries):
        provider = auto_provider.get_provider()
        start_time = time.time()
        try:
            response = ChatCompletion.create(
                model=model,
                messages=messages,
                stream=False,
                provider=provider,
                timeout=10
            )
            content = getattr(response, 'content', str(response))
            if content.strip():
                response_time = time.time() - start_time
                return True, response_time
        except Exception as e:
            logger.debug(f"Model {model} failed with provider {provider.__name__}: {str(e)}")
            auto_provider.mark_failed(provider)
            continue
    return False, None

def update_active_models_cache():
    """Update model states and response times in the background."""
    def background_check():
        for model in MODELS_TO_CHECK:
            model["state"] = "checking"
        for model in MODELS_TO_CHECK:
            active, response_time = is_model_active(model["name"])
            model["state"] = "enable" if active else "disable"
            model["rate"] = response_time if active else None
    threading.Thread(target=background_check).start()

def schedule_cache_update():
    """Schedule cache updates every 1 hour."""
    update_active_models_cache()
    threading.Timer(3600, schedule_cache_update).start()

def initialize_cache():
    """Initialize the model cache with all models set to 'checking'."""
    global MODELS_TO_CHECK
    extracted_models = extract_models_from_providers()
    MODELS_TO_CHECK = [{"name": model, "state": "checking", "rate": None} for model in extracted_models]
    schedule_cache_update()

# Initialize cache at startup
initialize_cache()

def get_active_model(exclude=None):
    """Get an active model, excluding specified models."""
    if exclude is None:
        exclude = []
    for model in MODELS_TO_CHECK:
        if model["state"] == "enable" and model["name"] not in exclude:
            return model["name"]
    return None

### Telegram Bot Setup
API_TOKEN = '1607789975:AAEInQBAiHoAULJ9j7n6mBfWSssJwJV0vBY'
bot = telebot.TeleBot(API_TOKEN)

# Persian greeting messages with emojis
PERSIAN_GREETINGS = [
    "Ø³Ù„Ø§Ù… {name} Ø¹Ø²ÛŒØ²! ğŸŒŸ Ø¨Ù‡ Ø±Ø¨Ø§Øª Ù‚ÛŒÙ…Øªâ€ŒÚ¯Ø°Ø§Ø±ÛŒ ÙÙˆÙ„Ø§Ø¯ Ø®ÙˆØ´ Ø¢Ù…Ø¯ÛŒØ¯. ğŸ—ï¸",
    "Ø¯Ø±ÙˆØ¯ {name}! ğŸš€ Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ§Ù… ØªØ§ Ø¯Ø± Ù…ÙˆØ±Ø¯ Ù‚ÛŒÙ…Øªâ€ŒÙ‡Ø§ÛŒ ÙÙˆÙ„Ø§Ø¯ Ø¨Ù‡ Ø´Ù…Ø§ Ú©Ù…Ú© Ú©Ù†Ù…. ğŸ› ï¸",
    "Ø®ÙˆØ´ Ø¢Ù…Ø¯ÛŒØ¯ {name}! ğŸ‰ Ú†Ú¯ÙˆÙ†Ù‡ Ù…ÛŒâ€ŒØªÙˆØ§Ù†Ù… Ø¯Ø± Ù…ÙˆØ±Ø¯ ÙÙˆÙ„Ø§Ø¯ Ø¨Ù‡ Ø´Ù…Ø§ Ú©Ù…Ú© Ú©Ù†Ù…ØŸ ğŸ“¦",
    "Ø³Ù„Ø§Ù… {name}! ğŸ˜Š Ø®ÙˆØ´Ø­Ø§Ù„Ù… Ú©Ù‡ Ø§ÛŒÙ†Ø¬Ø§ Ù‡Ø³ØªÛŒØ¯. Ø¨ÛŒØ§ÛŒÛŒØ¯ Ø¯Ø± Ù…ÙˆØ±Ø¯ Ù‚ÛŒÙ…Øªâ€ŒÙ‡Ø§ÛŒ ÙÙˆÙ„Ø§Ø¯ ØµØ­Ø¨Øª Ú©Ù†ÛŒÙ…. ğŸ’µ",
    "Ø³Ù„Ø§Ù… {name}! ğŸŒŸ Ø¨Ù‡ Ø±Ø¨Ø§Øª Ø§Ø·Ù„Ø§Ø¹Ø§Øª ÙÙˆÙ„Ø§Ø¯ Ø®ÙˆØ´ Ø¢Ù…Ø¯ÛŒØ¯. ğŸ”©",
    "Ø¯Ø±ÙˆØ¯ {name}! âš¡ Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ§Ù… ØªØ§ Ø¨Ù‡ Ø³ÙˆØ§Ù„Ø§Øª Ø´Ù…Ø§ Ø¯Ø± Ù…ÙˆØ±Ø¯ ÙÙˆÙ„Ø§Ø¯ Ù¾Ø§Ø³Ø® Ø¯Ù‡Ù…. ğŸ­",
    "Ø®ÙˆØ´ Ø¢Ù…Ø¯ÛŒØ¯ {name}! âœ¨ Ù‡Ø± Ø³ÙˆØ§Ù„ÛŒ Ø¯Ø± Ù…ÙˆØ±Ø¯ ÙÙˆÙ„Ø§Ø¯ Ø¯Ø§Ø±ÛŒØ¯ Ø¨Ù¾Ø±Ø³ÛŒØ¯. ğŸ“‹",
    "Ø³Ù„Ø§Ù… {name}! ğŸ¤ Ø¯Ø³ØªÛŒØ§Ø± Ù‚ÛŒÙ…Øªâ€ŒÚ¯Ø°Ø§Ø±ÛŒ ÙÙˆÙ„Ø§Ø¯ Ø´Ù…Ø§ Ø§ÛŒÙ†Ø¬Ø§Ø³Øª. ğŸ› ï¸",
    "Ø¯Ø±ÙˆØ¯ {name}! ğŸ“ˆ Ø¨ÛŒØ§ÛŒÛŒØ¯ Ø¨Ø§ Ù‡Ù… Ø¨Ù‡ Ø¨Ø±Ø±Ø³ÛŒ Ù‚ÛŒÙ…Øªâ€ŒÙ‡Ø§ÛŒ ÙÙˆÙ„Ø§Ø¯ Ø¨Ù¾Ø±Ø¯Ø§Ø²ÛŒÙ…. ğŸ“ˆ",
    "Ø³Ù„Ø§Ù… {name}! ğŸ† Ø¨Ù‡ Ø¯Ù†ÛŒØ§ÛŒ ÙÙˆÙ„Ø§Ø¯ Ø®ÙˆØ´ Ø¢Ù…Ø¯ÛŒØ¯. ğŸ—ï¸",
    "Ø®ÙˆØ´ Ø¢Ù…Ø¯ÛŒØ¯ {name}! ğŸ’¡ Ú©Ù†Ø¬Ú©Ø§Ùˆ Ø¯Ø± Ù…ÙˆØ±Ø¯ ÙÙˆÙ„Ø§Ø¯ Ù‡Ø³ØªÛŒØ¯ØŸ Ù…Ù† Ù¾Ø§Ø³Ø®â€ŒÙ‡Ø§ Ø±Ø§ Ø¯Ø§Ø±Ù…. ğŸ’¬",
    "Ø³Ù„Ø§Ù… {name}! ğŸ”§ Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ§Ù… ØªØ§ Ø¨Ù‡ Ø³ÙˆØ§Ù„Ø§Øª Ø´Ù…Ø§ Ø¯Ø± Ù…ÙˆØ±Ø¯ ÙÙˆÙ„Ø§Ø¯ Ù¾Ø§Ø³Ø® Ø¯Ù‡Ù…. ğŸ”§",
    "Ø¯Ø±ÙˆØ¯ {name}! ğŸŒŸ Ú†Ú¯ÙˆÙ†Ù‡ Ù…ÛŒâ€ŒØªÙˆØ§Ù†Ù… Ø§Ù…Ø±ÙˆØ² Ø¯Ø± Ù…ÙˆØ±Ø¯ Ù‚ÛŒÙ…Øªâ€ŒÙ‡Ø§ÛŒ ÙÙˆÙ„Ø§Ø¯ Ø¨Ù‡ Ø´Ù…Ø§ Ú©Ù…Ú© Ú©Ù†Ù…ØŸ ğŸ“¦",
    "Ø³Ù„Ø§Ù… {name}! âš™ï¸ Ø±Ø¨Ø§Øª Ú©Ø§Ø±Ø´Ù†Ø§Ø³ ÙÙˆÙ„Ø§Ø¯ Ø´Ù…Ø§ Ø¢Ù†Ù„Ø§ÛŒÙ† Ø§Ø³Øª. ğŸ­",
    "Ø®ÙˆØ´ Ø¢Ù…Ø¯ÛŒØ¯ {name}! ğŸš€ Ø¨Ø§ Ù…Ù† Ø´Ø±ÙˆØ¹ Ø¨Ù‡ Ú©Ø§ÙˆØ´ Ø¯Ø± Ù‚ÛŒÙ…Øªâ€ŒÙ‡Ø§ÛŒ ÙÙˆÙ„Ø§Ø¯ Ú©Ù†ÛŒØ¯. ğŸ› ï¸"
]

def get_categories():
    """Get list of categories from sheets folder, excluding main.csv."""
    sheets_dir = 'sheets'
    files = os.listdir(sheets_dir)
    categories = [f.replace('.csv', '') for f in files if f.endswith('.csv') and f != 'main.csv']
    return categories

def get_category_data(category):
    """Fetch data for a specific category."""
    file_path = f'sheets/{category}.csv'
    if os.path.exists(file_path):
        return pd.read_csv(file_path)
    return pd.DataFrame()

def get_main_data():
    """Fetch data from main.csv."""
    file_path = 'sheets/main.csv'
    if os.path.exists(file_path):
        return pd.read_csv(file_path)
    return pd.DataFrame()

### Streaming GPT Response
def stream_gpt_response(chat_id, prompt, relevant_category=None):
    """Stream GPT response by editing a Telegram message with cancel option."""
    main_df = get_main_data()
    categories = get_categories()
    
    # Prepare main.csv data with emojis
    main_info = "\n".join(
        [f"ğŸ“Œ {row['Ø¯Ø³ØªÙ‡ Ø¨Ù†Ø¯ÛŒ']}: {row['Ø¬Ø²Ø¦ÛŒØ§Øª Ù…Ø­ØµÙˆÙ„ ( Ø¯Ø³ØªÙ‡ Ø¨Ù†Ø¯ÛŒ )']} - ğŸ’° Ù‚ÛŒÙ…Øª Ù¾Ø§ÛŒÙ‡: {row['Ù‚ÛŒÙ…Øª Ù¾Ø§ÛŒÙ‡ Ù…Ø­ØµÙˆÙ„']}" 
         for _, row in main_df.iterrows()]
    ) if not main_df.empty else "âš ï¸ Ø¯Ø§Ø¯Ù‡â€ŒØ§ÛŒ Ø¯Ø± main.csv Ù…ÙˆØ¬ÙˆØ¯ Ù†ÛŒØ³Øª."

    # Prepare category-specific data if relevant with emojis
    if relevant_category and relevant_category in categories:
        category_df = get_category_data(relevant_category)
        category_info = "\n".join(
            [f"ğŸ”¹ {row.to_dict()}" for _, row in category_df.iterrows()]
        ) if not category_df.empty else f"âš ï¸ Ø¯Ø§Ø¯Ù‡â€ŒØ§ÛŒ Ø¨Ø±Ø§ÛŒ Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒ {relevant_category} Ù…ÙˆØ¬ÙˆØ¯ Ù†ÛŒØ³Øª."
    else:
        category_info = "ğŸ” Ù‡ÛŒÚ† Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒ Ø®Ø§ØµÛŒ Ø¯Ø± Ù¾ÛŒØ§Ù… Ø´Ù…Ø§ ÛŒØ§ÙØª Ù†Ø´Ø¯."
    categories_show = "\n".join(categories)

    # Professional prompt with emoji suggestion
    full_prompt = f"""
    # Ù†Ù‚Ø´: Ø¯Ø³ØªÛŒØ§Ø± Ø¨Ø±Ø±Ø³ÛŒ Ù‚ÛŒÙ…Øª Ø¢Ù‡Ù† Ø¢Ù„Ø§Øª  
    # Ù†Ø§Ù…: SteelBot  
    ## ğŸ—ï¸ Ø´Ø±ÙˆØ¹ Ù…Ú©Ø§Ù„Ù…Ù‡ (Ø³Ø§Ø¯Ù‡ Ùˆ Ø¹Ù…Ù„ÛŒ)  
    "Ø³Ù„Ø§Ù… ÙÙˆÙ„Ø§Ø¯ÛŒ! ğŸ”©  
    Ù‚ÛŒÙ…Øª Ù…Ø­ØµÙˆÙ„Ø§Øª ÙÙˆÙ„Ø§Ø¯ÛŒ Ù†ÛŒØ§Ø² Ø¯Ø§Ø±ÛŒØŸ ğŸ¯  
    Ù„ÛŒØ³Øª Ù‚ÛŒÙ…Øªâ€ŒÙ‡Ø§ Ù…Ø³ØªÙ‚ÛŒÙ…Ø§Ù‹ Ø§Ø² Ø¯ÛŒØªØ§Ø¨ÛŒØ³ Ù…Ø§ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…ÛŒØ´Ù‡! ğŸ“Š"  
    # Ø²Ø¨Ø§Ù†: ÙØ§Ø±Ø³ÛŒ  
    # Ù†Ú©ØªÙ‡: Ù¾Ø§Ø³Ø®â€ŒÙ‡Ø§ Ø¨Ø§ÛŒØ¯ Ø¯Ù‚ÛŒÙ‚Ø§Ù‹ Ù…Ø·Ø§Ø¨Ù‚ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø´ÛŒØª Ùˆ Ø¨Ø§ ÙØ±Ù…Øª ØµØ­ÛŒØ­ Ø§Ø±Ø§Ø¦Ù‡ Ø´ÙˆÙ†Ø¯.  
    # Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯: Ø¯Ø± Ù¾Ø§Ø³Ø®â€ŒÙ‡Ø§ Ø§Ø² Ø§ÛŒÙ…ÙˆØ¬ÛŒâ€ŒÙ‡Ø§ÛŒÛŒ Ù…Ø«Ù„ ğŸ“ŒØŒ ğŸ’°ØŒ ğŸ”¹ØŒ âš ï¸ØŒ ğŸ¯ØŒ ğŸ“Š Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯ ØªØ§ Ø¬Ø°Ø§Ø¨â€ŒØªØ± Ø´ÙˆÙ†Ø¯.

    Ú©Ø§Ø±Ø¨Ø± Ù¾Ø±Ø³ÛŒØ¯Ù‡: {prompt}
    
    Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø§ØµÙ„ÛŒ (Ù…Ø­ØµÙˆÙ„Ø§Øª Ù¾Ø±Ø·Ø±ÙØ¯Ø§Ø±):  
    {main_info}

    ØªÙ…Ø§Ù… Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒ Ù…ÙˆØ¬ÙˆØ¯ :
    {categories_show}
    
    Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒ Ù…Ø±ØªØ¨Ø·:  
    {category_info}
    
    Ù„Ø·ÙØ§Ù‹ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø§ÛŒÙ† Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ØŒ Ø¨Ù‡ ÙØ§Ø±Ø³ÛŒ Ø³Ø§Ø¯Ù‡ Ùˆ Ù…Ø®ØªØµØ± Ù¾Ø§Ø³Ø® Ø¯Ù‡ÛŒØ¯ Ùˆ Ø§Ø² Ø§ÛŒÙ…ÙˆØ¬ÛŒâ€ŒÙ‡Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯.
    """

    # Send initial message and set cancel flag
    sent_message = bot.send_message(chat_id, "â³ Ø¯Ø± Ø­Ø§Ù„ Ù¾Ø±Ø¯Ø§Ø²Ø´...")
    cancel_flags[sent_message.message_id] = False
    attempted_models = []

    while True:
        model = get_active_model(exclude=attempted_models)
        if not model:
            bot.edit_message_text("âš ï¸ Ù…ØªØ§Ø³ÙØ§Ù†Ù‡ Ø¯Ø± Ø­Ø§Ù„ Ø­Ø§Ø¶Ø± Ù‡ÛŒÚ† Ù…Ø¯Ù„ÛŒ Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ù†ÛŒØ³Øª.", chat_id, sent_message.message_id)
            return
        attempted_models.append(model)

        bot.edit_message_text(f"â³ Ø¯Ø± Ø­Ø§Ù„ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø¨Ø§ Ù…Ø¯Ù„ {model}...", chat_id, sent_message.message_id)

        messages = [{"role": "user", "content": full_prompt}]
        
        retries = len(ACTIVE_PROVIDERS)
        for attempt in range(retries):
            provider = auto_provider.get_provider()
            try:
                response = ChatCompletion.create(
                    model=model,
                    messages=messages,
                    stream=True,
                    provider=provider,
                    timeout=30
                )

                accumulated_response = ""
                last_edit_time = time.time()

                try:
                    for chunk in response:
                        if cancel_flags.get(sent_message.message_id, False):
                            bot.edit_message_text("âŒ Ø¹Ù…Ù„ÛŒØ§Øª Ù„ØºÙˆ Ø´Ø¯.", chat_id, sent_message.message_id)
                            return
                        content = getattr(chunk, 'content', str(chunk))
                        accumulated_response += content
                        if time.time() - last_edit_time > 0.2:
                            markup = InlineKeyboardMarkup()
                            markup.add(InlineKeyboardButton("âŒ Ù„ØºÙˆ Ø¹Ù…Ù„ÛŒØ§Øª âŒ", callback_data='cancel'))
                            bot.edit_message_text(accumulated_response, chat_id, sent_message.message_id, reply_markup=markup)
                            last_edit_time = time.time()
                    
                    # Final response text
                    final_text = accumulated_response

                    # Prepare inline keyboard with emojis
                    markup = InlineKeyboardMarkup()
                    if relevant_category:
                        markup.add(InlineKeyboardButton(f"ğŸ“¦ Ù…Ø­ØµÙˆÙ„Ø§Øª {relevant_category.replace('_', ' ')}", 
                                                       switch_inline_query_current_chat=f"/category_{relevant_category}"))
                    else:
                        # Suggest some categories with emojis
                        suggested_categories = random.sample(categories, min(3, len(categories)))
                        for cat in suggested_categories:
                            markup.add(InlineKeyboardButton(f"ğŸ”¹ Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒ {cat.replace('_', ' ')}", 
                                                           switch_inline_query_current_chat=f"/category_{cat}"))
                    
                    markup.add(InlineKeyboardButton("ğŸ“‹ Ù„ÛŒØ³Øª Ù‡Ù…Ù‡ Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒâ€ŒÙ‡Ø§", switch_inline_query_current_chat="/categories"))
                    
                    bot.edit_message_text(final_text, chat_id, sent_message.message_id, reply_markup=markup)
                    return
                finally:
                    if sent_message.message_id in cancel_flags:
                        del cancel_flags[sent_message.message_id]

            except Exception as e:
                logger.warning(f"Provider {provider.__name__} failed for model {model}: {str(e)}")
                auto_provider.mark_failed(provider)
                if attempt == retries - 1:
                    break
                time.sleep(2 ** attempt)

        bot.edit_message_text(f"âš ï¸ Ø®Ø·Ø§ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø¨Ø§ Ù…Ø¯Ù„ {model}. Ø¯Ø± Ø­Ø§Ù„ ØªÙ„Ø§Ø´ Ø¨Ø§ Ù…Ø¯Ù„ Ø¯ÛŒÚ¯Ø±...", chat_id, sent_message.message_id)
        time.sleep(1)

### Bot Handlers
@bot.message_handler(commands=['start'])
def send_welcome(message):
    name = message.from_user.first_name
    welcome_text = random.choice(PERSIAN_GREETINGS).format(name=name)
    
    markup = InlineKeyboardMarkup()
    markup.row(
        InlineKeyboardButton("ğŸ“¦ Ù…Ø­ØµÙˆÙ„Ø§Øª", switch_inline_query_current_chat='/products'),
        InlineKeyboardButton("ğŸ·ï¸ Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒ", switch_inline_query_current_chat='/categories')
    )
    markup.add(InlineKeyboardButton("â“ Ø±Ø§Ù‡Ù†Ù…Ø§", callback_data='help'))
    
    bot.send_message(message.chat.id, welcome_text, reply_markup=markup)

@bot.callback_query_handler(func=lambda call: True)
def handle_callback(call):
    if call.data == 'help':
        help_text = "ğŸ“˜ Ø±Ø§Ù‡Ù†Ù…Ø§ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡:\n- 'ğŸ“¦ Ù…Ø­ØµÙˆÙ„Ø§Øª' Ø¨Ø±Ø§ÛŒ Ø¯ÛŒØ¯Ù† Ù…Ø­ØµÙˆÙ„Ø§Øª Ù¾Ø±Ø·Ø±ÙØ¯Ø§Ø±\n- 'ğŸ·ï¸ Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒ' Ø¨Ø±Ø§ÛŒ Ù„ÛŒØ³Øª Ø¯Ø³ØªÙ‡â€ŒÙ‡Ø§\n- Ø³ÙˆØ§Ù„Ø§Øª Ø®ÙˆØ¯ Ø±Ø§ Ù…Ø³ØªÙ‚ÛŒÙ… Ø¨Ù¾Ø±Ø³ÛŒØ¯ ğŸ“"
        bot.answer_callback_query(call.id, help_text, show_alert=True)
    
    elif call.data == 'cancel':
        message_id = call.message.message_id
        if message_id in cancel_flags:
            cancel_flags[message_id] = True
            bot.answer_callback_query(call.id, "âŒ Ø¹Ù…Ù„ÛŒØ§Øª Ø¯Ø± Ø­Ø§Ù„ Ù„ØºÙˆ Ø§Ø³Øª...")
        else:
            bot.answer_callback_query(call.id, "âœ… Ø¹Ù…Ù„ÛŒØ§Øª Ù‚Ø¨Ù„Ø§ Ø¨Ù‡ Ù¾Ø§ÛŒØ§Ù† Ø±Ø³ÛŒØ¯Ù‡ Ø§Ø³Øª.")

@bot.inline_handler(lambda query: query.query == '/products')
def show_products(inline_query):
    df = get_main_data()
    if df.empty:
        results = [InlineQueryResultArticle(
            id=str(uuid.uuid4()),
            title="âš ï¸ Ø®Ø·Ø§",
            input_message_content=InputTextMessageContent("ğŸ·ï¸ Ù‡ÛŒÚ† Ù…Ø­ØµÙˆÙ„ÛŒ Ø¯Ø± main.csv ÛŒØ§ÙØª Ù†Ø´Ø¯ ÛŒØ§ Ø®Ø§Ù„ÛŒ Ø§Ø³Øª.")
        )]
    else:
        df_limited = df.head(50)  # Limit to 50 results
        results = []
        for index, row in df_limited.iterrows():
            content = (
                f"ğŸ”¸ Ú©Ø¯ Ù…Ø­ØµÙˆÙ„: {row['Ú©Ø¯ Ù…Ø­ØµÙˆÙ„']}\n"
                f"ğŸ·ï¸ Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒ: {row['Ø¯Ø³ØªÙ‡ Ø¨Ù†Ø¯ÛŒ']}\n"
                f"ğŸ“‹ Ø¬Ø²Ø¦ÛŒØ§Øª: {row['Ø¬Ø²Ø¦ÛŒØ§Øª Ù…Ø­ØµÙˆÙ„ ( Ø¯Ø³ØªÙ‡ Ø¨Ù†Ø¯ÛŒ )']}\n"
                f"ğŸ’° Ù‚ÛŒÙ…Øª Ù¾Ø§ÛŒÙ‡: {row['Ù‚ÛŒÙ…Øª Ù¾Ø§ÛŒÙ‡ Ù…Ø­ØµÙˆÙ„']}\n"
                f"ğŸ“¦ Ù…ÙˆØ¬ÙˆØ¯ÛŒ: {row['Ù…ÙˆØ¬ÙˆØ¯ÛŒ Ù…Ø­ØµÙˆÙ„']}"
            )
            unique_id = str(uuid.uuid4())
            results.append(
                InlineQueryResultArticle(
                    id=unique_id,
                    title=f"{row['Ø¬Ø²Ø¦ÛŒØ§Øª Ù…Ø­ØµÙˆÙ„ ( Ø¯Ø³ØªÙ‡ Ø¨Ù†Ø¯ÛŒ )']}",
                    description=f"ğŸ’° {row['Ù‚ÛŒÙ…Øª Ù¾Ø§ÛŒÙ‡ Ù…Ø­ØµÙˆÙ„']} - ğŸ“¦ {row['Ù…ÙˆØ¬ÙˆØ¯ÛŒ Ù…Ø­ØµÙˆÙ„']}",
                    input_message_content=InputTextMessageContent(content)
                )
            )
    bot.answer_inline_query(inline_query.id, results)

@bot.inline_handler(lambda query: query.query == '/categories')
def show_categories(inline_query):
    categories = get_categories()
    results = []
    for cat in categories:
        unique_id = str(uuid.uuid4())
        results.append(
            InlineQueryResultArticle(
                id=unique_id,
                title=cat.replace('_', ' '),
                description=f"ğŸ“¦ Ù…Ø´Ø§Ù‡Ø¯Ù‡ Ù…Ø­ØµÙˆÙ„Ø§Øª Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒ {cat.replace('_', ' ')}",
                input_message_content=InputTextMessageContent(f"ğŸ·ï¸ Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒ: {cat.replace('_', ' ')}"),
                reply_markup=InlineKeyboardMarkup().add(
                    InlineKeyboardButton("ğŸ‘€ Ù…Ø´Ø§Ù‡Ø¯Ù‡ Ù…Ø­ØµÙˆÙ„Ø§Øª", switch_inline_query_current_chat=f"/category_{cat}")
                )
            )
        )
    bot.answer_inline_query(inline_query.id, results)

@bot.inline_handler(lambda query: query.query.startswith('/category_'))
def show_category_products(inline_query):
    category = inline_query.query.replace('/category_', '')
    df = get_category_data(category)
    if df.empty:
        results = [InlineQueryResultArticle(
            id=str(uuid.uuid4()),
            title="âš ï¸ Ø®Ø·Ø§",
            input_message_content=InputTextMessageContent(f"ğŸ·ï¸ Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒ {category.replace('_', ' ')} ÛŒØ§ÙØª Ù†Ø´Ø¯ ÛŒØ§ Ø®Ø§Ù„ÛŒ Ø§Ø³Øª.")
        )]
    else:
        df_limited = df.head(50)  # Limit to 50 results
        results = []
        for index, row in df_limited.iterrows():
            content = "\n".join([f"ğŸ”¸ {col}: {val}" for col, val in row.to_dict().items()])
            unique_id = str(uuid.uuid4())
            results.append(
                InlineQueryResultArticle(
                    id=unique_id,
                    title=row.get('Ù†Ø§Ù…', f"Ù…Ø­ØµÙˆÙ„ {index + 1}"),  # Adjust based on actual column names
                    description=f"ğŸ“‹ Ø¬Ø²Ø¦ÛŒØ§Øª Ù…Ø­ØµÙˆÙ„ Ø§Ø² {category.replace('_', ' ')}",
                    input_message_content=InputTextMessageContent(content)
                )
            )
    bot.answer_inline_query(inline_query.id, results)

@bot.message_handler(func=lambda message: True)
def handle_message(message):
    categories = get_categories()
    # Check if message contains any category name
    relevant_category = next((cat for cat in categories if cat.replace('_', ' ').strip() in message.text), None)
    stream_gpt_response(message.chat.id, message.text, relevant_category)

### Main Loop
if __name__ == '__main__':
    print("Bot is running... ğŸš€")
    bot.infinity_polling()